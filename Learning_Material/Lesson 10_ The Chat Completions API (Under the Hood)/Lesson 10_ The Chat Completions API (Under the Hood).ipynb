{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7895344c-409c-4f7c-948a-56000c2797c3",
   "metadata": {},
   "source": [
    "# Module 2: Frontier Models\n",
    "## Lesson 10: The Chat Completions API (Under the Hood)\n",
    "\n",
    "### üìÑ Overview\n",
    "Before relying on the convenient Python client libraries, this lesson breaks down the fundamental protocol of modern AI: the **Chat Completions API**. We perform a \"Raw\" HTTP request to understand exactly what data is being sent over the wire.\n",
    "\n",
    "### üóùÔ∏è Key Concepts\n",
    "* **Chat Completions:** The industry-standard format for LLM interaction. You provide a list of message objects (history), and the model \"completes\" the conversation by predicting the next message.\n",
    "* **The Endpoint:** A specific URL (e.g., `https://api.openai.com/v1/chat/completions`) that accepts JSON payloads and returns JSON predictions.\n",
    "* **Client Libraries vs. Raw HTTP:**\n",
    "    * **Client Library (`openai`)**: A Python wrapper that handles connection pooling, error retries, and converts JSON to Python objects.\n",
    "    * **Raw HTTP**: The fundamental layer. Useful for debugging or when you are in a language without a supported library.\n",
    "\n",
    "### üõ†Ô∏è Technical Implementation: The \"Raw\" Request\n",
    "*Instead of `client.chat.completions.create`, we use the standard `requests` library to build the packet manually.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ebfaf4-7a8d-4143-a2f5-d3986854d20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# 1. Define the Endpoint\n",
    "url = \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "# 2. Define the Headers (Authentication & Content Type)\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"  # The standard Bearer Token pattern\n",
    "}\n",
    "\n",
    "# 3. Define the Payload (The exact JSON schema OpenAI expects)\n",
    "payload = {\n",
    "    \"model\": \"gpt-4o-mini\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Tell me a fun fact about HTTP.\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(f\"üì° Sending POST request to {url}...\")\n",
    "\n",
    "# 4. Make the Request\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "\n",
    "# 5. Parse the JSON Response\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    \n",
    "    # Navigating the dictionary manually (The \"Messy\" part)\n",
    "    content = data['choices'][0]['message']['content']\n",
    "    \n",
    "    print(\"\\n‚úÖ Success!\")\n",
    "    print(f\"Response: {content}\")\n",
    "    print(f\"\\nFull JSON Structure:\\n{json.dumps(data, indent=2)}\")\n",
    "else:\n",
    "    print(f\"‚ùå Error {response.status_code}: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f70a62-9ca6-453d-81a2-a456b7340680",
   "metadata": {},
   "source": [
    "### üß™ Lab Notes & Engineering Log\n",
    "\n",
    "*The following experiments focus on API Mechanics.*\n",
    "\n",
    "#### Experiment 1: Why use the Library?\n",
    "**Comparison:**\n",
    "* **Raw HTTP (Above):** Requires manual header management, manual JSON parsing (`data['choices'][0]...`), and no built-in error handling.\n",
    "* **Python Library:** Handles retries, types, and offers dot-notation (`response.choices[0]`).\n",
    "* **Conclusion:** Use Raw HTTP only for debugging or extremely lightweight scripts where installing the full `openai` package is overkill.\n",
    "\n",
    "#### Experiment 2: Inspecting the \"Usage\" Field\n",
    "**Observation:**\n",
    "In the raw JSON output above, I can clearly see the `usage` dictionary.\n",
    "```json\n",
    "\"usage\": {\n",
    "  \"prompt_tokens\": 14,\n",
    "  \"completion_tokens\": 12,\n",
    "  \"total_tokens\": 26\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
