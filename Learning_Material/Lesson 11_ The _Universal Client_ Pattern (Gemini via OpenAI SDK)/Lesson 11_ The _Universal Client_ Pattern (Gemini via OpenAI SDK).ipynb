{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "828fe142-f638-405c-9232-45c0930169e0",
   "metadata": {},
   "source": [
    "# Module 2: Frontier Models\n",
    "## Lesson 11: The \"Universal Client\" Pattern (Gemini via OpenAI SDK)\n",
    "\n",
    "### üìÑ Overview\n",
    "The \"Chat Completions\" API format (List of Messages -> JSON Response) has become the `de facto` standard for the AI industry. As a result, we don't need to learn a new library for every provider. We can simply point the standard `openai` client to a different URL.\n",
    "\n",
    "### üóùÔ∏è Key Concepts\n",
    "* **Standardization:** Most Frontier Labs (Google, Anthropic, Groq, Mistral) now offer \"OpenAI-Compatible Endpoints.\"\n",
    "* **The `base_url` Parameter:** This is the magic switch. By default, the client points to `api.openai.com`. If we change this to Google's endpoint, the client sends the exact same JSON packet to Google instead.\n",
    "* **Vendor Agnosticism:** This pattern allows engineers to swap models (e.g., move from GPT-4 to Gemini) by changing *configuration*, not *code logic*.\n",
    "\n",
    "### üõ†Ô∏è Technical Implementation\n",
    "To talk to Google Gemini using the OpenAI SDK, we need:\n",
    "1.  **Google API Key:** Get this from [Google AI Studio](https://aistudio.google.com/).\n",
    "2.  **Base URL:** Usually `https://generativelanguage.googleapis.com/v1beta/openai/` (Note: verify current endpoint in docs).\n",
    "\n",
    "*Note: The instructor mentions \"Gemini 2.5/3\". In the code below, we use the current production model `gemini-1.5-flash`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a834764-730f-4530-9e04-377c1df75b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# 1. Retrieve the Google API Key (Add GOOGLE_API_KEY to your .env file first!)\n",
    "google_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if not google_key:\n",
    "    print(\"‚ùå Error: Missing GOOGLE_API_KEY in .env\")\n",
    "else:\n",
    "    print(\"‚úÖ Found Google Key.\")\n",
    "\n",
    "# 2. Initialize the Client with a Custom Base URL\n",
    "# This tells the library: \"Don't go to OpenAI. Go here instead.\"\n",
    "gemini_client = OpenAI(\n",
    "    api_key=google_key,\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "\n",
    "# 3. Make the Request (Identical syntax to previous lessons)\n",
    "print(\"üåç Calling Google Gemini...\")\n",
    "\n",
    "try:\n",
    "    response = gemini_client.chat.completions.create(\n",
    "        model=\"gemini-1.5-flash\",  # Use a valid Gemini model name\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"Tell me a fun fact about flamingos.\"}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # 4. Extract Result\n",
    "    print(\"\\n--- Gemini Response ---\")\n",
    "    print(response.choices[0].message.content)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f871ca-80f6-4716-abef-164db5b15944",
   "metadata": {},
   "source": [
    "### üß™ Lab Notes & Engineering Log\n",
    "\n",
    "*The following experiments focus on Cross-Provider Compatibility.*\n",
    "\n",
    "#### Experiment 1: The \"Drop-in Replacement\" Test\n",
    "**Objective:** Verify if I can swap providers without breaking my `messages_for` function from Lesson 6.\n",
    "**Test:**\n",
    "1.  I used the *exact same* list of dictionaries `[{\"role\": \"user\" ...}]`.\n",
    "2.  I sent it to Gemini.\n",
    "3.  **Result:** Success. The schema is identical.\n",
    "4.  **Implication:** I can write my entire application logic *once* and switch providers based on cost or availability just by changing a config file.\n",
    "\n",
    "#### Experiment 2: Error Handling differences\n",
    "**Observation:**\n",
    "While the *request* is standard, the *errors* might differ.\n",
    "* OpenAI returns `RateLimitError`.\n",
    "* Google might return a 400 or 429 with different text.\n",
    "* **Best Practice:** When building robust apps, we still need to catch generic `Exception` or map provider-specific errors if using advanced features.\n",
    "\n",
    "#### Experiment 3: Finding the Endpoint\n",
    "**Challenge:** Google's OpenAI-compatible endpoint URL changes occasionally as it moves from Beta to V1.\n",
    "**Action:** I bookmarked the [Google AI Studio API Docs](https://ai.google.dev/) to ensure I have the correct `base_url`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
