{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "178a82c1-5bf7-4664-becf-19a57191e0bb",
   "metadata": {},
   "source": [
    "# Module 1: Course Introduction & Local Setup\n",
    "## Lesson 5: First API Call & System Prompts\n",
    "\n",
    "### üìÑ Overview\n",
    "In this lesson, we graduate from local setup to writing actual code that interacts with the OpenAI API. We learn the strict JSON structure required by the Chat Completions API and explore how to control the model's behavior using **System Prompts**.\n",
    "\n",
    "### üóùÔ∏è Key Concepts\n",
    "* **Chat Completions API**: The standard endpoint (`chat.completions.create`) used by almost all modern LLM providers.\n",
    "* **Message Roles**:\n",
    "    * **`system`**: Sets the behavior, tone, and rules (The \"God Mode\" instruction).\n",
    "    * **`user`**: The actual input or question from the end-user.\n",
    "    * **`assistant`**: The response generated by the model (used for history).\n",
    "* **Statelessness**: The API does not remember you. Every time you call it, you must send the entire conversation history if you want context.\n",
    "\n",
    "### üõ†Ô∏è Technical Implementation\n",
    "The core object is a **List of Dictionaries**, where each dictionary represents a message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cad275-b0aa-4579-a4d8-5c897a4a9430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# 1. Load Environment Variables\n",
    "# This looks for the .env file we created in Lesson 4\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    print(\"‚ùå Error: API Key not found!\")\n",
    "else:\n",
    "    print(\"‚úÖ API Key loaded.\")\n",
    "\n",
    "# 2. Initialize the Client\n",
    "# This client handles the connection pooling and authentication for us\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620cb295-9348-4f13-8d33-e6ec0840bb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the conversation\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"Hello GPT, this is my first ever message to you via Python code!\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 2. Make the API Call\n",
    "# We use 'gpt-4o-mini' which is the current cost-effective standard\n",
    "print(\"Sending request to OpenAI...\")\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "# 3. Extract and Print the content\n",
    "# The response object contains metadata (usage, id, etc.) + the choices\n",
    "ai_message = response.choices[0].message.content\n",
    "print(\"\\n--- AI Response ---\")\n",
    "print(ai_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6dda88-4de4-4625-ba5e-a618e42aaf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_gpt(user_query, system_behavior):\n",
    "    \"\"\"\n",
    "    A helper function to test different system personas.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_behavior},\n",
    "            {\"role\": \"user\", \"content\": user_query}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Test 1: Helpful Assistant\n",
    "print(\"--- üòá Helpful ---\")\n",
    "print(ask_gpt(\"What is 2 + 2?\", \"You are a helpful math tutor.\"))\n",
    "\n",
    "# Test 2: Snarky Assistant\n",
    "print(\"\\n--- üòà Snarky ---\")\n",
    "print(ask_gpt(\"What is 2 + 2?\", \"You are a snarky, sarcastic assistant who hates answering simple questions.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c6aede-b033-42e5-808a-c088daf77a71",
   "metadata": {},
   "source": [
    "### üß™ Lab Notes & Engineering Log\n",
    "\n",
    "*The following experiments focus on Persona Injection and API Inspection.*\n",
    "\n",
    "#### Experiment 1: Persona Stress Test\n",
    "**Objective:** See how strictly the model adheres to the system prompt.\n",
    "**Test:**\n",
    "* **System Prompt:** *\"You are a Cowboy from 1850. You do not know what computers are.\"*\n",
    "* **User Prompt:** *\"Help me fix my Python bug.\"*\n",
    "\n",
    "#### Experiment 2: Inspecting the Full Response Object\n",
    "**Objective:** As engineers, we need to know how much this cost.\n",
    "**Code Modification:**\n",
    "```python\n",
    "full_response = client.chat.completions.create(model=\"gpt-4o-mini\", messages=[...])\n",
    "print(full_response.usage)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
